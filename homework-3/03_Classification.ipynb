{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9af04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 292 293\n",
      "Validation accuracy: 0.72\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 38  78]\n",
      " [  4 172]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.905     0.328     0.481       116\n",
      "           1      0.688     0.977     0.808       176\n",
      "\n",
      "    accuracy                          0.719       292\n",
      "   macro avg      0.796     0.652     0.644       292\n",
      "weighted avg      0.774     0.719     0.678       292\n",
      "\n",
      "Test accuracy: 0.75\n",
      "Saved dv and model.\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "CSV_URL = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "\n",
    "def download_if_needed(path=\"course_lead_scoring.csv\"):\n",
    "    if not pd.io.common.file_exists(path):\n",
    "        wget.download(CSV_URL, path)\n",
    "    return path\n",
    "\n",
    "csv_path = download_if_needed()\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()\n",
    "df.isnull().sum()\n",
    "\n",
    "# For caterogiral features, replace them with 'NA'\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')\n",
    "# For numerical features, replace with with 0.0\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "# verify if all missing values are replaced\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "# 5. Define target and features\n",
    "target = 'converted'   # converted = 1 if signed up, else 0\n",
    "y = df[target].values\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# 6. Shuffle and split: 60% train, 20% val, 20% test (seed=42)\n",
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "n = len(df_shuffled)\n",
    "train_end = int(0.6 * n)\n",
    "val_end = train_end + int(0.2 * n)\n",
    "\n",
    "df_train = df_shuffled.iloc[:train_end].reset_index(drop=True)\n",
    "df_val   = df_shuffled.iloc[train_end:val_end].reset_index(drop=True)\n",
    "df_test  = df_shuffled.iloc[val_end:].reset_index(drop=True)\n",
    "\n",
    "X_train = df_train.drop(columns=[target])\n",
    "y_train = df_train[target].values\n",
    "X_val = df_val.drop(columns=[target])\n",
    "y_val = df_val[target].values\n",
    "X_test = df_test.drop(columns=[target])\n",
    "y_test = df_test[target].values\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))\n",
    "\n",
    "# 7. Vectorize features (DictVectorizer)\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# convert DF -> list of dicts\n",
    "train_dicts = X_train.to_dict(orient='records')\n",
    "X_train_vec = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = X_val.to_dict(orient='records')\n",
    "X_val_vec = dv.transform(val_dicts)\n",
    "\n",
    "test_dicts = X_test.to_dict(orient='records')\n",
    "X_test_vec = dv.transform(test_dicts)\n",
    "\n",
    "# 8. Train Logistic Regression\n",
    "model = LogisticRegression(C=1.0, solver='liblinear', max_iter=1000, random_state=42)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 9. Predict on validation set and compute accuracy\n",
    "y_val_pred = model.predict(X_val_vec)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation accuracy:\", round(acc_val, 2))   # expect ~0.84\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_val, y_val_pred, digits=3))\n",
    "\n",
    "# 10. Final evaluation on test set (optional)\n",
    "y_test_pred = model.predict(X_test_vec)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test accuracy:\", round(acc_test, 2))\n",
    "\n",
    "# 11. Save model + vectorizer for serving\n",
    "joblib.dump(dv, \"dict_vectorizer.joblib\")\n",
    "joblib.dump(model, \"logreg_model.joblib\")\n",
    "print(\"Saved dv and model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef22c0",
   "metadata": {},
   "source": [
    "Q1: What is the most frequent observation (mode) for the column industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6c5915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5523ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'interaction_count and lead_score': np.float64(0.009888182496913105),\n",
       " 'number_of_courses_viewed and lead_score': np.float64(-0.004878998354681265),\n",
       " 'number_of_courses_viewed and interaction_count': np.float64(-0.023565222882888055),\n",
       " 'annual_income and interaction_count': np.float64(0.027036472404814396)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr=df.corr(numeric_only=True)\n",
    "corr_pairs = {\n",
    "    \"interaction_count and lead_score\": corr.loc[\"interaction_count\", \"lead_score\"],\n",
    "    \"number_of_courses_viewed and lead_score\": corr.loc[\"number_of_courses_viewed\", \"lead_score\"],\n",
    "    \"number_of_courses_viewed and interaction_count\": corr.loc[\"number_of_courses_viewed\", \"interaction_count\"],\n",
    "    \"annual_income and interaction_count\": corr.loc[\"annual_income\", \"interaction_count\"],\n",
    "}\n",
    "\n",
    "corr_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bb353",
   "metadata": {},
   "source": [
    "Ans: annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baa1dd",
   "metadata": {},
   "source": [
    "Q2: Question 3. Biggest MI (1 point)\n",
    "\n",
    "industry\n",
    "\n",
    "location\n",
    "\n",
    "lead_source\n",
    "\n",
    "employment_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05ea79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry': 0.007267435279688886,\n",
       " 'location': 0.0014269064526338665,\n",
       " 'lead_source': 0.026573987738060995,\n",
       " 'employment_status': 0.011069560968622674}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "# categorical features\n",
    "cat_features = [\"industry\", \"location\", \"lead_source\", \"employment_status\"]\n",
    "\n",
    "# target variable\n",
    "target = df[\"converted\"]\n",
    "\n",
    "# compute mutual information for each categorical feature\n",
    "mi_scores = {col: mutual_info_score(df[col], target) for col in cat_features}\n",
    "\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3939911c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1462 non-null   object \n",
      " 1   industry                  1462 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1462 non-null   float64\n",
      " 4   employment_status         1462 non-null   object \n",
      " 5   location                  1462 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "employment_status\n",
       "self_employed    352\n",
       "student          348\n",
       "unemployed       334\n",
       "employed         328\n",
       "NA               100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df['industry'].value_counts()\n",
    "df['employment_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de78329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['industry', 'employment_status'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b11e5412",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1072800364.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mmi_scores = pd.Series(mi_scores, index=\u001b[39m\n                         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = df_encoded.drop('target', axis=1)\n",
    "y = df_encoded['target']\n",
    "print(df_encoded.columns)\n",
    "\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "mi_scores = pd.Series(mi_scores, index=\n",
    "X = df_encoded.drop('converted', axis=1)  # features\n",
    "y = df_encoded['converted']               # target.columns)\n",
    "mi_scores.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68608c",
   "metadata": {},
   "source": [
    "Ans: lead_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
